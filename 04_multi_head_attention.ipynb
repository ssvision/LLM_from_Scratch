{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size: int, num_heads: int, bias: bool = False):\n",
    "        super.__init__()\n",
    "        assert hidden_size%num_heads == 0\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        ''' linear layer to generate Q,K,V matrice'''\n",
    "        self.Wqkv = nn.Linear(hidden_size, hidden_size*3, bias=bias)\n",
    "\n",
    "        '''final projection layer'''\n",
    "        self.Wo = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "\n",
    "        ''' add droput layers'''\n",
    "        self.attn_dropout = nn.Dropout(p=0.1)\n",
    "        self.out_dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, X:torch.Tensor):\n",
    "        \n",
    "        '''B=batch size, S=sequence length, C=input dimension'''\n",
    "        B, S, C = X.shape\n",
    "\n",
    "        ''' split into q, k, v '''\n",
    "        _attn = self.Wqkv(X).reshape(B,S,3,self.num_heads,C//self.num_heads)\n",
    "        q, k, v = _attn.transpose(3,1).unbind(dim=2)\n",
    "\n",
    "        '''compute dot product of q and k transpose'''\n",
    "        attn = q@k.transpose(-2,-1)\n",
    "        '''scale the dot product by dk'''\n",
    "        attn=attn/math.sqrt(k.size(-1))\n",
    "        '''softmax the output'''\n",
    "        attn=attn.softmax(dim=-1)\n",
    "        '''add dropout to attention'''\n",
    "        attn=self.attn_dropout(attn)\n",
    "        '''dot product with v'''\n",
    "        attn = attn @ v\n",
    "\n",
    "        '''final projected output'''\n",
    "        proj_op = self.Wo(attn.transpose(1,2).reshape(B,S,C))\n",
    "\n",
    "        return self.out_dropout(proj_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation below with example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size: int, num_heads: int, bias: bool = False):\n",
    "        super().__init__()\n",
    "        assert hidden_size%num_heads == 0\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        ''' linear layer to generate Q,K,V matrice'''\n",
    "        self.Wqkv = nn.Linear(hidden_size, hidden_size*3, bias=bias)\n",
    "\n",
    "        '''final projection layer'''\n",
    "        self.Wo = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "\n",
    "    def forward(self, X:torch.Tensor):\n",
    "        B, S, C = X.shape\n",
    "\n",
    "        attn = self.Wqkv(X)\n",
    "\n",
    "        return attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_network = MultiHeadAttention(8, 2) #hidden_dim=embedding_dim=8 , num_heads=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= torch.randn(1,3,8)  # assume input batch_size=1, seq_len=3, hidden_dim=8\n",
    "output = attn_network(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 24])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5973,  0.2666,  0.2746,  0.4936,  0.6298,  0.4234,  0.4988,\n",
       "           0.0929, -0.3498,  0.1395,  0.3523, -0.6470, -1.6516,  0.0221,\n",
       "          -0.8677, -0.2388,  0.3012,  0.7000,  0.7043,  0.1389,  0.3321,\n",
       "           0.0668,  0.1967,  0.3129],\n",
       "         [ 1.1910, -0.0927,  0.3379,  0.7205,  0.1519, -0.6670,  0.0610,\n",
       "           0.7899, -0.8511, -0.9471,  0.1259, -0.1026, -0.6632,  0.1835,\n",
       "          -0.6266, -1.1363, -0.3523,  0.9304, -0.0053,  0.4833, -0.8110,\n",
       "          -0.1459,  0.0292,  0.4406],\n",
       "         [ 0.8885, -0.7931,  0.5758,  1.5568,  0.1038, -0.8108,  0.6113,\n",
       "          -0.1354, -1.1147, -0.6673,  0.7566,  0.4825, -0.2541,  0.4908,\n",
       "           0.0200, -0.2089, -0.3127,  1.8513, -0.6349, -0.6648, -0.6157,\n",
       "          -0.7970,  0.1724, -0.1503]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.reshape(1, 3, 3, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 1.5973,  0.2666,  0.2746,  0.4936],\n",
       "           [ 0.6298,  0.4234,  0.4988,  0.0929]],\n",
       "\n",
       "          [[-0.3498,  0.1395,  0.3523, -0.6470],\n",
       "           [-1.6516,  0.0221, -0.8677, -0.2388]],\n",
       "\n",
       "          [[ 0.3012,  0.7000,  0.7043,  0.1389],\n",
       "           [ 0.3321,  0.0668,  0.1967,  0.3129]]],\n",
       "\n",
       "\n",
       "         [[[ 1.1910, -0.0927,  0.3379,  0.7205],\n",
       "           [ 0.1519, -0.6670,  0.0610,  0.7899]],\n",
       "\n",
       "          [[-0.8511, -0.9471,  0.1259, -0.1026],\n",
       "           [-0.6632,  0.1835, -0.6266, -1.1363]],\n",
       "\n",
       "          [[-0.3523,  0.9304, -0.0053,  0.4833],\n",
       "           [-0.8110, -0.1459,  0.0292,  0.4406]]],\n",
       "\n",
       "\n",
       "         [[[ 0.8885, -0.7931,  0.5758,  1.5568],\n",
       "           [ 0.1038, -0.8108,  0.6113, -0.1354]],\n",
       "\n",
       "          [[-1.1147, -0.6673,  0.7566,  0.4825],\n",
       "           [-0.2541,  0.4908,  0.0200, -0.2089]],\n",
       "\n",
       "          [[-0.3127,  1.8513, -0.6349, -0.6648],\n",
       "           [-0.6157, -0.7970,  0.1724, -0.1503]]]]],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 1.5973,  0.2666,  0.2746,  0.4936],\n",
       "           [ 1.1910, -0.0927,  0.3379,  0.7205],\n",
       "           [ 0.8885, -0.7931,  0.5758,  1.5568]],\n",
       "\n",
       "          [[-0.3498,  0.1395,  0.3523, -0.6470],\n",
       "           [-0.8511, -0.9471,  0.1259, -0.1026],\n",
       "           [-1.1147, -0.6673,  0.7566,  0.4825]],\n",
       "\n",
       "          [[ 0.3012,  0.7000,  0.7043,  0.1389],\n",
       "           [-0.3523,  0.9304, -0.0053,  0.4833],\n",
       "           [-0.3127,  1.8513, -0.6349, -0.6648]]],\n",
       "\n",
       "\n",
       "         [[[ 0.6298,  0.4234,  0.4988,  0.0929],\n",
       "           [ 0.1519, -0.6670,  0.0610,  0.7899],\n",
       "           [ 0.1038, -0.8108,  0.6113, -0.1354]],\n",
       "\n",
       "          [[-1.6516,  0.0221, -0.8677, -0.2388],\n",
       "           [-0.6632,  0.1835, -0.6266, -1.1363],\n",
       "           [-0.2541,  0.4908,  0.0200, -0.2089]],\n",
       "\n",
       "          [[ 0.3321,  0.0668,  0.1967,  0.3129],\n",
       "           [-0.8110, -0.1459,  0.0292,  0.4406],\n",
       "           [-0.6157, -0.7970,  0.1724, -0.1503]]]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output.transpose(3,1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 3, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.5973,  0.2666,  0.2746,  0.4936],\n",
       "          [ 1.1910, -0.0927,  0.3379,  0.7205],\n",
       "          [ 0.8885, -0.7931,  0.5758,  1.5568]],\n",
       "\n",
       "         [[ 0.6298,  0.4234,  0.4988,  0.0929],\n",
       "          [ 0.1519, -0.6670,  0.0610,  0.7899],\n",
       "          [ 0.1038, -0.8108,  0.6113, -0.1354]]]], grad_fn=<UnbindBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q,k,v = output.unbind(dim=2)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
